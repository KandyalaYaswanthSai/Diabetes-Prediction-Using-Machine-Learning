from sklearn.preprocessing import StandardScaler, LabelEncoder
import pandas as pd
diabetes_data=pd.read_csv('/content/Dataset of Diabetes .csv')

diabetes_data.head()

diabetes_data.tail()

diabetes_data.describe()

diabetes_data.shape

diabetes_data.columns

diabetes_data.dtypes

import warnings
warnings.filterwarnings("ignore")
diabetes_data.nunique()

diabetes_data.isnull().sum()

diabetes_data.nunique()

diabetes_data['Gender'].value_counts()

diabetes_data['Chol'].value_counts()

diabetes_data['CLASS'].value_counts()

diabetes_data['Gender'] = label_encoder.fit_transform(diabetes_data['Gender'])
diabetes_data['Gender'] = diabetes_data['Gender'].astype(float)
print(diabetes_data.head())

diabetes_data.corr()

diabetes_data.groupby('CLASS').describe()

diabetes_data.hist(bins=30, figsize=(15, 10))

import seaborn as sns
import matplotlib.pyplot as plt
# Heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(numeric_data.corr(), annot=True, cmap='coolwarm')
plt.title("Heatmap of the correlation matrix")
plt.show()

# Convert categorical variables to numerical
label_encoder = LabelEncoder()
diabetes_data['Gender'] = label_encoder.fit_transform(diabetes_data['Gender'])
diabetes_data['CLASS'] = label_encoder.fit_transform(diabetes_data['CLASS'])

# Drop non-predictive columns
diabetes_data = diabetes_data.drop(columns=['ID', 'No_Pation'])

# Verify the dataset
print(diabetes_data.info())

# Scaling
scaler = StandardScaler()
scaled_features = scaler.fit_transform(diabetes_data.drop('CLASS', axis=1))

# Creating new DataFrame with scaled features
scaled_diabetes_data = pd.DataFrame(scaled_features, columns=diabetes_data.columns[:-1])
scaled_diabetes_data['CLASS'] = diabetes_data['CLASS']

# Display the scaled data
print(scaled_diabetes_data.head())

# Calculate the correlation matrix
correlation_matrix = scaled_diabetes_data.corr()

# Display the correlation matrix
print(correlation_matrix)

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')
plt.show()


from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report

# Splitting the dataset
X = scaled_diabetes_data.drop('CLASS', axis=1)
y = scaled_diabetes_data['CLASS']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


# Hyperparameter tuning with RandomForestClassifier
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_features': ['auto', 'sqrt', 'log2'],
    'max_depth': [4, 6, 8, 10, 12],
    'criterion': ['gini', 'entropy']
}
grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train, y_train)


# Best parameters from GridSearchCV
print("Best Parameters from GridSearchCV:")
print(grid_search.best_params_)


# Train model using the best parameters
best_model = grid_search.best_estimator_
best_model.fit(X_train, y_train)

# Test model
y_pred = best_model.predict(X_test)


from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

print("Performance Metrics:")
accuracy = accuracy_score(y_test, y_pred)

# For multiclass classification, you need to specify the average parameter
precision = precision_score(y_test, y_pred, average='macro')  
recall = recall_score(y_test, y_pred, average='macro')        
f1 = f1_score(y_test, y_pred, average='macro')                

print("Accuracy: ",accuracy)
print("Precision: ",precision)
print("Recall:",recall)
print("F1 Score: ",f1)

# Predict the values
sample_predictions = best_model.predict(X_test[:3])
print("Predictions for 3 samples:")
print(sample_predictions)
